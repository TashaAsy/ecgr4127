{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKh7hoNYUmbN","executionInfo":{"status":"ok","timestamp":1708815222854,"user_tz":300,"elapsed":13406,"user":{"displayName":"David Nichols","userId":"03285782024896652237"}},"outputId":"57a502b9-245e-4f55-b14f-797f256b090d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model converted to TFLite with int8 quantization and saved successfully!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# Load the previously saved model\n","model_path = 'sin_predictor.h5'  # Make sure to have the correct path\n","model = load_model(model_path)\n","\n","# Retrieve input shape from the model\n","input_shape = model.input_shape[1:]  # This excludes the batch size dimension\n","\n","# Representative dataset generator\n","def representative_data_gen():\n","    for _ in range(100):  # Adjust the number of samples as needed\n","        # Generate a sample using the input shape. Replace with real data if available.\n","        yield [np.random.random((1,) + input_shape).astype(np.float32)]\n","\n","# Set up the converter for int8 quantization\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.int8]\n","converter.representative_dataset = representative_data_gen\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8\n","converter.inference_output_type = tf.int8\n","\n","# Convert the model\n","tflite_quant_model = converter.convert()\n","\n","# Save the TFLite model to a file\n","with open('sin_predictor.tflite', 'wb') as f:\n","    f.write(tflite_quant_model)\n","\n","print(\"Model converted to TFLite with int8 quantization and saved successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVsExsDcUmbQ","executionInfo":{"status":"ok","timestamp":1708815222854,"user_tz":300,"elapsed":6,"user":{"displayName":"David Nichols","userId":"03285782024896652237"}},"outputId":"bd619728-acc9-4620-c9e7-9159902c8be1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input details:\n","Name: serving_default_input_1:0, Shape: [1 7], Type: <class 'numpy.int8'>\n","\n","Output details:\n","Name: StatefulPartitionedCall:0, Shape: [1 1], Type: <class 'numpy.int8'>\n"]}],"source":["# Load the TFLite model\n","tflite_model_path = 'sin_predictor.tflite'\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","\n","# Allocate tensors to the interpreter\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Print input and output details\n","print(\"Input details:\")\n","for input_detail in input_details:\n","    print(f\"Name: {input_detail['name']}, Shape: {input_detail['shape']}, Type: {input_detail['dtype']}\")\n","\n","print(\"\\nOutput details:\")\n","for output_detail in output_details:\n","    print(f\"Name: {output_detail['name']}, Shape: {output_detail['shape']}, Type: {output_detail['dtype']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYcSTRuiUmbQ"},"outputs":[],"source":["!xxd sin_predictor.tflite sin_predictor.cc"]}],"metadata":{"kernelspec":{"display_name":"tf-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}